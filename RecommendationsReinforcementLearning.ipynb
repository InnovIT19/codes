{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32f69036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9aad17c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClothingRecommendationEnv:\n",
    "    def __init__(self, body_measurements, gender, style_preference, skin_tone):\n",
    "        self.body_measurements = body_measurements\n",
    "        self.gender = gender\n",
    "        self.style_preference = style_preference\n",
    "        self.skin_tone = skin_tone\n",
    "        self.state = self._get_initial_state()\n",
    "        self.rewards = self._initialize_rewards()\n",
    "\n",
    "    def _get_initial_state(self):\n",
    "        state = np.array([\n",
    "            self.body_measurements['height'],\n",
    "            1 if self.gender == 'male' else 0,\n",
    "            0 if self.style_preference == 'full_body' else 1 if self.style_preference == 'upper_body' else 2,\n",
    "            self.skin_tone\n",
    "        ])\n",
    "        return state\n",
    "\n",
    "    def _initialize_rewards(self):\n",
    "        # Example: Assuming 100 states with 4 possible actions each\n",
    "        rewards = np.random.rand(100, 4)\n",
    "        return rewards\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = self._get_initial_state()\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        # For simplicity, keep state unchanged\n",
    "        new_state = self.state\n",
    "        # Simplified indexing of rewards for the current state\n",
    "        state_index = int(sum(self.state)) % 100  # Example: simple hashing to map to rewards\n",
    "        reward = self.rewards[state_index, action]\n",
    "        return new_state, reward\n",
    "\n",
    "# Example usage\n",
    "body_measurements = {'height': 170,}\n",
    "gender = 'female'\n",
    "style_preference = 'upper_body'\n",
    "skin_tone = 4  # Example value for skin tone\n",
    "env = ClothingRecommendationEnv(body_measurements, gender, style_preference, skin_tone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66573bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN:\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        self.w1 = np.random.randn(input_dim, hidden_dim)\n",
    "        self.b1 = np.zeros(hidden_dim)\n",
    "        self.w2 = np.random.randn(hidden_dim, output_dim)\n",
    "        self.b2 = np.zeros(output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.z1 = np.dot(x, self.w1) + self.b1\n",
    "        self.a1 = np.maximum(0, self.z1)  # ReLU activation\n",
    "        self.z2 = np.dot(self.a1, self.w2) + self.b2\n",
    "        return self.z2\n",
    "    \n",
    "    def backward(self, x, y, y_pred, learning_rate):\n",
    "        loss = y_pred - y\n",
    "        dz2 = loss\n",
    "        dw2 = np.dot(self.a1.T, dz2)\n",
    "        db2 = np.sum(dz2, axis=0)\n",
    "\n",
    "        dz1 = np.dot(dz2, self.w2.T)\n",
    "        dz1[self.z1 <= 0] = 0\n",
    "        dw1 = np.dot(x.T, dz1)\n",
    "        db1 = np.sum(dz1, axis=0)\n",
    "\n",
    "        self.w1 -= learning_rate * dw1\n",
    "        self.b1 -= learning_rate * db1\n",
    "        self.w2 -= learning_rate * dw2\n",
    "        self.b2 -= learning_rate * db2\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.forward(x)\n",
    "\n",
    "# Example usage\n",
    "nn = SimpleNN(input_dim=4, hidden_dim=10, output_dim=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac22c951",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, env, learning_rate=0.001, gamma=0.99, epsilon=0.2):\n",
    "        self.env = env\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.q_network = SimpleNN(input_dim=4, hidden_dim=10, output_dim=4)\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return np.random.choice(3)  # Random action\n",
    "        q_values = self.q_network.predict(state)\n",
    "        return np.argmax(q_values)\n",
    "\n",
    "    def learn(self, state, action, reward, next_state):\n",
    "        q_values = self.q_network.predict(state)\n",
    "        next_q_values = self.q_network.predict(next_state)\n",
    "\n",
    "        target = q_values.copy()\n",
    "        target[0, action] = reward + self.gamma * np.max(next_q_values)\n",
    "\n",
    "        self.q_network.backward(state, q_values, target, self.learning_rate)\n",
    "\n",
    "    def train(self, episodes=10):\n",
    "        for _ in range(episodes):\n",
    "            state = self.env.reset()\n",
    "            state = np.expand_dims(state, axis=0)\n",
    "            while True:\n",
    "                action = self.choose_action(state)\n",
    "                next_state, reward = self.env.step(action)\n",
    "                next_state = np.expand_dims(next_state, axis=0)\n",
    "                self.learn(state, action, reward, next_state)\n",
    "                if np.array_equal(state, next_state):  # Add a condition to prevent infinite loops\n",
    "                    break\n",
    "                state = next_state\n",
    "\n",
    "    def recommend(self, state):\n",
    "        state = np.expand_dims(state, axis=0)\n",
    "        q_values = self.q_network.predict(state)\n",
    "        return np.argmax(q_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a19433b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended action: 3\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Mock Data\n",
    "body_measurements = {'height': 165,}\n",
    "gender = 'female'\n",
    "style_preference = 'upper_body'\n",
    "skin_tone = 1  # Example value for skin tone\n",
    "\n",
    "# Step 2: Initialize the Environment\n",
    "env = ClothingRecommendationEnv(body_measurements, gender, style_preference, skin_tone)\n",
    "\n",
    "# Step 3: Train the Agent\n",
    "agent = Agent(env)\n",
    "agent.train(episodes=10)\n",
    "\n",
    "# Step 4: Make a Recommendation\n",
    "current_state = env.reset()\n",
    "recommendation = agent.recommend(current_state)\n",
    "print(f\"Recommended action: {recommendation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9d3055",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
